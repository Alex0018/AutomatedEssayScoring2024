{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hawkins\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "\n",
    "from src.config import ProjectPaths, CFG, seed_everything\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "from src.experiment import experiment\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED=42\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "model_name = 'microsoft/deberta-v3-small'\n",
    "\n",
    "config = {\n",
    "          'project_name': 'EssayScoring_LLM_features',\n",
    "          'run_name': f'{model_name.split(\"/\")[-1]}_cluster3_unfeeze2_fold_{fold}',\n",
    "          'create_dataloaders_func': 'EssayClassifier',\n",
    "          'data_parameters': {\n",
    "              'model_name': model_name,\n",
    "              'batch_size': 1,      \n",
    "              'fold': fold,\n",
    "              'path_df': ProjectPaths.train_cluster3       \n",
    "          }  ,\n",
    "          'loss': 'CrossEntropy',\n",
    "          'optimizer': 'AdamW', \n",
    "          'learning_rate': 1e-5,\n",
    "          'epochs': 10,\n",
    "          'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "          'model': 'EssayClassifier',\n",
    "          'model_parameters': {\n",
    "              'model_name': model_name,\n",
    "          }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Kaggle\\EssayScoring\\wandb\\run-20240626_202144-dutgkftx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nasonova-alexandra/EssayScoring_LLM_features/runs/dutgkftx' target=\"_blank\">deberta-v3-small_cluster3_unfeeze2_fold_0</a></strong> to <a href='https://wandb.ai/nasonova-alexandra/EssayScoring_LLM_features' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nasonova-alexandra/EssayScoring_LLM_features' target=\"_blank\">https://wandb.ai/nasonova-alexandra/EssayScoring_LLM_features</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nasonova-alexandra/EssayScoring_LLM_features/runs/dutgkftx' target=\"_blank\">https://wandb.ai/nasonova-alexandra/EssayScoring_LLM_features/runs/dutgkftx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---------------------------------------------------------------------------------------------------- \n",
      "   Number of trainable parameters in model:  4614 \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 0 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    mean loss  1.69584     kappa  0.18675: 100%|██████████| 1318/1318 [01:37<00:00, 13.51it/s]\n",
      "validation batch:    mean loss  1.36372     kappa -0.19048: 100%|██████████| 330/330 [00:21<00:00, 15.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  1.69584      metric  0.00922\n",
      "\tvalidation:  loss  1.36372      metric -0.10293\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 1 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    mean loss  1.29693     kappa -0.10526: 100%|██████████| 1318/1318 [01:37<00:00, 13.45it/s]\n",
      "validation batch:    mean loss  1.22975     kappa -0.22378: 100%|██████████| 330/330 [00:22<00:00, 14.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  1.29693      metric -0.10742\n",
      "\tvalidation:  loss  1.22975      metric -0.00961\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "   Number of trainable parameters in model:  141308934 \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 2 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    mean loss  0.99705     kappa  0.48980: 100%|██████████| 1318/1318 [06:54<00:00,  3.18it/s]\n",
      "validation batch:    mean loss  0.87500     kappa  0.57746: 100%|██████████| 330/330 [00:22<00:00, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  0.99705      metric  0.43709\n",
      "\tvalidation:  loss  0.87500      metric  0.50725\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 3 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    mean loss  0.73417     kappa  0.76316: 100%|██████████| 1318/1318 [06:53<00:00,  3.19it/s]\n",
      "validation batch:    mean loss  0.76564     kappa  0.71338: 100%|██████████| 330/330 [00:22<00:00, 14.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  0.73417      metric  0.69763\n",
      "\tvalidation:  loss  0.76564      metric  0.65819\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 4 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    mean loss  0.63746     kappa  0.78049: 100%|██████████| 1318/1318 [06:50<00:00,  3.21it/s]\n",
      "validation batch:    mean loss  0.74630     kappa  0.74286: 100%|██████████| 330/330 [00:21<00:00, 15.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  0.63746      metric  0.76485\n",
      "\tvalidation:  loss  0.74630      metric  0.69684\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 5 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    mean loss  0.53372     kappa  0.81670: 100%|██████████| 1318/1318 [06:48<00:00,  3.22it/s]\n",
      "validation batch:    mean loss  0.71328     kappa  0.79042: 100%|██████████| 330/330 [00:21<00:00, 15.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  0.53372      metric  0.81872\n",
      "\tvalidation:  loss  0.71328      metric  0.71423\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 6 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    mean loss  0.44287     kappa  0.92116: 100%|██████████| 1318/1318 [06:51<00:00,  3.20it/s]\n",
      "validation batch:    mean loss  0.75267     kappa  0.80226: 100%|██████████| 330/330 [00:22<00:00, 14.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  0.44287      metric  0.85001\n",
      "\tvalidation:  loss  0.75267      metric  0.70827\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 7 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    mean loss  0.34015     kappa  0.85437: 100%|██████████| 1318/1318 [06:57<00:00,  3.16it/s]\n",
      "validation batch:    mean loss  0.83149     kappa  0.79042: 100%|██████████| 330/330 [00:22<00:00, 14.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  0.34015      metric  0.89251\n",
      "\tvalidation:  loss  0.83149      metric  0.69860\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 8 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    mean loss  0.27052     kappa  0.95816: 100%|██████████| 1318/1318 [06:53<00:00,  3.19it/s]\n",
      "validation batch:    mean loss  0.86357     kappa  0.77987: 100%|██████████| 330/330 [00:21<00:00, 15.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  0.27052      metric  0.92288\n",
      "\tvalidation:  loss  0.86357      metric  0.71500\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 9 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    mean loss  0.21492     kappa  0.97778: 100%|██████████| 1318/1318 [06:53<00:00,  3.19it/s]\n",
      "validation batch:    mean loss  1.02369     kappa  0.79381: 100%|██████████| 330/330 [00:22<00:00, 14.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  0.21492      metric  0.93695\n",
      "\tvalidation:  loss  1.02369      metric  0.68067\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss_train</td><td>█▆▅▃▃▃▂▂▁▁</td></tr><tr><td>loss_valid</td><td>█▇▃▂▁▁▁▂▃▄</td></tr><tr><td>metric_train</td><td>▂▁▅▆▇▇▇███</td></tr><tr><td>metric_valid</td><td>▁▂▆███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss_train</td><td>0.21492</td></tr><tr><td>loss_valid</td><td>1.02369</td></tr><tr><td>metric_train</td><td>0.93695</td></tr><tr><td>metric_valid</td><td>0.68067</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deberta-v3-small_cluster3_unfeeze2_fold_0</strong> at: <a href='https://wandb.ai/nasonova-alexandra/EssayScoring_LLM_features/runs/dutgkftx' target=\"_blank\">https://wandb.ai/nasonova-alexandra/EssayScoring_LLM_features/runs/dutgkftx</a><br/>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240626_202144-dutgkftx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "\n",
    "# device = torch.device('cuda')\n",
    "\n",
    "# checkpoint = torch.load('trained_models/441a4m4s_checkpoint.pth')\n",
    "\n",
    "# model = EssayClassifierModel('microsoft/deberta-v3-xsmall')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# model = model.to(device)\n",
    "\n",
    "# dataloader_train, dataloader_valid = create_dataloaders(ProjectPaths.train, fold=0, model_name='microsoft/deberta-v3-xsmall', batch_size=1)\n",
    "\n",
    "\n",
    "# outputs = np.empty(len(dataloader_valid), dtype=int)\n",
    "# targets = np.empty(len(dataloader_valid), dtype=int)\n",
    "\n",
    "# for b, batch in enumerate(tqdm(dataloader_valid)):\n",
    "#     output = model(collate_batch(batch['inputs']).to(device)).cpu().detach().numpy().argmax(axis=1)\n",
    "#     target = batch['labels'].cpu().detach().numpy()\n",
    "#     outputs[b] = output\n",
    "#     targets[b] = target\n",
    "\n",
    "# print('outputs', outputs)\n",
    "# print('targets', targets)\n",
    "# score = cohen_kappa_score(targets, outputs, weights='quadratic')\n",
    "# print('score', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
